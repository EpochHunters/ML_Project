{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GppFo18kSCo9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GppFo18kSCo9",
    "outputId": "c448a3c4-8f19-4eac-dd1e-29142a6ea418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7uTwMh9a3EPX",
   "metadata": {
    "id": "7uTwMh9a3EPX"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/New Approach/models') # append the directory containing the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e3d02",
   "metadata": {
    "id": "4b1e3d02"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import EncoderEEG\n",
    "import deepcnn\n",
    "import cnn2dlstm\n",
    "import cnn1dlstm\n",
    "import traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jnd1kYenHg0n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnd1kYenHg0n",
    "outputId": "8b68608a-9783-4b72-8cd6-8df26f01e124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'traintest' from '/content/drive/MyDrive/New Approach/models/traintest.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(traintest) # reload the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g4eXuZGjGY0m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4eXuZGjGY0m",
    "outputId": "cf4562ed-3c1d-4bb5-93da-4c75d3bb50a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b916f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a8b916f",
    "outputId": "d416c308-0734-47f1-eaf6-3d3f0c97c010",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d39b2ac6a785>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset=torch.load(r\"/content/drive/MyDrive/Data/eeg_55_95_std.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02389026', 'n03888257', 'n03584829', 'n02607072', 'n03297495', 'n03063599', 'n03792782', 'n04086273', 'n02510455', 'n11939491', 'n02951358', 'n02281787', 'n02106662', 'n04120489', 'n03590841', 'n02992529', 'n03445777', 'n03180011', 'n02906734', 'n07873807', 'n03773504', 'n02492035', 'n03982430', 'n03709823', 'n03100240', 'n03376595', 'n03877472', 'n03775071', 'n03272010', 'n04069434', 'n03452741', 'n03792972', 'n07753592', 'n13054560', 'n03197337', 'n02504458', 'n02690373', 'n03272562', 'n04044716', 'n02124075']\n"
     ]
    }
   ],
   "source": [
    "dataset=torch.load(r\"/content/drive/MyDrive/Data/eeg_55_95_std.pth\")\n",
    "labels=dataset['labels']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b6665",
   "metadata": {
    "id": "543b6665"
   },
   "outputs": [],
   "source": [
    "data=dataset['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3932698",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3932698",
    "outputId": "1c220081-a9b0-45de-f5d2-7ad3de10fb2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-02f78271f0ac>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  splits=torch.load(r\"/content/drive/MyDrive/Data/block_splits_by_image_all.pth\")\n"
     ]
    }
   ],
   "source": [
    "splits=torch.load(r\"/content/drive/MyDrive/Data/block_splits_by_image_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b63d9",
   "metadata": {
    "id": "5d2b63d9"
   },
   "outputs": [],
   "source": [
    "x_train,x_val,x_test,y_train,y_val,y_test=traintest.Splitter(dataset,splits,subject_no=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edb441",
   "metadata": {
    "id": "43edb441"
   },
   "outputs": [],
   "source": [
    "# For using 2D CNN or similar models, we need to add an extra dimension to our data for which we can use unsqueeze function\n",
    "\n",
    "x_train=torch.stack(x_train)\n",
    "#x_train=x_train.unsqueeze(3)\n",
    "x_val=torch.stack(x_val)\n",
    "#x_val=x_val.unsqueeze(3)\n",
    "x_test=torch.stack(x_test)\n",
    "#x_test=x_test.unsqueeze(3)\n",
    "y_train=torch.tensor(y_train)\n",
    "y_val=torch.tensor(y_val)\n",
    "y_test=torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IK1_sKZiKX04",
   "metadata": {
    "id": "IK1_sKZiKX04"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187c2e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8187c2e1",
    "outputId": "c3008625-44c6-4ecd-aa68-1cdd62cdfde5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGEncoder(\n",
      "  (temporal_block): TemporalBlock(\n",
      "    (network): Sequential(\n",
      "      (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(3,))\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(6,), dilation=(2,))\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(12,), dilation=(4,))\n",
      "      (5): ReLU()\n",
      "      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(24,), dilation=(8,))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (spatial_block): SpatialBlock(\n",
      "    (network): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (res_blocks): ModuleList(\n",
      "    (0-1): 2 x ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=32, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes = 40\n",
    "learning_rate = 0.005\n",
    "num_epochs = 50\n",
    "\n",
    "model = EncoderEEG.EEGEncoder(num_classes=40).to(device)\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff4590",
   "metadata": {
    "id": "e9ff4590"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val,y_val)\n",
    "test_dataset = TensorDataset(x_test,y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95e399",
   "metadata": {
    "id": "2b95e399"
   },
   "outputs": [],
   "source": [
    "#for inputs,labels in train_loader:\n",
    " #   print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6408d1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6408d1a",
    "outputId": "c4fc493d-2c41-40a5-9a2a-c20748082937",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 3.6681, Validation Loss: 3.6328, Training Accuracy: 3.14%, Validation Accuracy: 2.40%\n",
      "Epoch 2/50, Training Loss: 3.5224, Validation Loss: 3.4731, Training Accuracy: 4.09%, Validation Accuracy: 4.30%\n",
      "Epoch 3/50, Training Loss: 3.2692, Validation Loss: 3.1000, Training Accuracy: 5.50%, Validation Accuracy: 7.56%\n",
      "Epoch 4/50, Training Loss: 2.9927, Validation Loss: 3.1904, Training Accuracy: 7.69%, Validation Accuracy: 6.16%\n",
      "Epoch 5/50, Training Loss: 2.7882, Validation Loss: 2.6539, Training Accuracy: 9.79%, Validation Accuracy: 12.06%\n",
      "Epoch 6/50, Training Loss: 2.6276, Validation Loss: 2.5618, Training Accuracy: 11.04%, Validation Accuracy: 11.21%\n",
      "Epoch 7/50, Training Loss: 2.5078, Validation Loss: 2.5470, Training Accuracy: 13.96%, Validation Accuracy: 14.66%\n",
      "Epoch 8/50, Training Loss: 2.4525, Validation Loss: 2.3131, Training Accuracy: 13.96%, Validation Accuracy: 15.82%\n",
      "Epoch 9/50, Training Loss: 2.3989, Validation Loss: 2.3749, Training Accuracy: 14.69%, Validation Accuracy: 14.26%\n",
      "Epoch 10/50, Training Loss: 2.2886, Validation Loss: 2.4680, Training Accuracy: 16.95%, Validation Accuracy: 12.96%\n",
      "Epoch 11/50, Training Loss: 2.2324, Validation Loss: 2.3786, Training Accuracy: 17.63%, Validation Accuracy: 15.22%\n",
      "Epoch 12/50, Training Loss: 2.1723, Validation Loss: 2.1229, Training Accuracy: 18.86%, Validation Accuracy: 19.72%\n",
      "Epoch 13/50, Training Loss: 2.1380, Validation Loss: 2.0936, Training Accuracy: 20.18%, Validation Accuracy: 20.87%\n",
      "Epoch 14/50, Training Loss: 2.0572, Validation Loss: 2.0016, Training Accuracy: 22.07%, Validation Accuracy: 23.77%\n",
      "Epoch 15/50, Training Loss: 2.0611, Validation Loss: 2.0980, Training Accuracy: 22.10%, Validation Accuracy: 21.82%\n",
      "Epoch 16/50, Training Loss: 1.9840, Validation Loss: 2.0339, Training Accuracy: 23.40%, Validation Accuracy: 20.57%\n",
      "Epoch 17/50, Training Loss: 1.9255, Validation Loss: 1.9182, Training Accuracy: 24.99%, Validation Accuracy: 25.03%\n",
      "Epoch 18/50, Training Loss: 1.8833, Validation Loss: 2.0837, Training Accuracy: 26.17%, Validation Accuracy: 23.87%\n",
      "Epoch 19/50, Training Loss: 1.8612, Validation Loss: 1.8558, Training Accuracy: 27.06%, Validation Accuracy: 26.18%\n",
      "Epoch 20/50, Training Loss: 1.8208, Validation Loss: 1.8426, Training Accuracy: 28.18%, Validation Accuracy: 27.98%\n",
      "Epoch 21/50, Training Loss: 1.7879, Validation Loss: 1.8875, Training Accuracy: 28.76%, Validation Accuracy: 27.68%\n",
      "Epoch 22/50, Training Loss: 1.7609, Validation Loss: 1.8561, Training Accuracy: 29.32%, Validation Accuracy: 28.28%\n",
      "Epoch 23/50, Training Loss: 1.7451, Validation Loss: 1.7871, Training Accuracy: 29.81%, Validation Accuracy: 28.53%\n",
      "Epoch 24/50, Training Loss: 1.7373, Validation Loss: 1.7414, Training Accuracy: 30.51%, Validation Accuracy: 29.63%\n",
      "Epoch 25/50, Training Loss: 1.7088, Validation Loss: 1.7829, Training Accuracy: 30.99%, Validation Accuracy: 30.03%\n",
      "Epoch 26/50, Training Loss: 1.6599, Validation Loss: 1.8940, Training Accuracy: 32.23%, Validation Accuracy: 28.68%\n",
      "Epoch 27/50, Training Loss: 1.6491, Validation Loss: 1.8946, Training Accuracy: 33.31%, Validation Accuracy: 27.53%\n",
      "Epoch 28/50, Training Loss: 1.6370, Validation Loss: 1.7841, Training Accuracy: 33.51%, Validation Accuracy: 30.13%\n",
      "Epoch 29/50, Training Loss: 1.5939, Validation Loss: 1.6879, Training Accuracy: 35.07%, Validation Accuracy: 32.63%\n",
      "Epoch 30/50, Training Loss: 1.6005, Validation Loss: 1.8109, Training Accuracy: 34.64%, Validation Accuracy: 29.58%\n",
      "Epoch 31/50, Training Loss: 1.5580, Validation Loss: 1.7384, Training Accuracy: 36.55%, Validation Accuracy: 34.23%\n",
      "Epoch 32/50, Training Loss: 1.5534, Validation Loss: 1.6440, Training Accuracy: 36.16%, Validation Accuracy: 32.48%\n",
      "Epoch 33/50, Training Loss: 1.5323, Validation Loss: 1.6433, Training Accuracy: 37.05%, Validation Accuracy: 32.93%\n",
      "Epoch 34/50, Training Loss: 1.4875, Validation Loss: 1.7232, Training Accuracy: 39.18%, Validation Accuracy: 31.98%\n",
      "Epoch 35/50, Training Loss: 1.5178, Validation Loss: 1.7790, Training Accuracy: 37.11%, Validation Accuracy: 29.73%\n",
      "Epoch 36/50, Training Loss: 1.4682, Validation Loss: 1.7890, Training Accuracy: 39.37%, Validation Accuracy: 31.73%\n",
      "Epoch 37/50, Training Loss: 1.4606, Validation Loss: 1.5933, Training Accuracy: 38.76%, Validation Accuracy: 36.29%\n",
      "Epoch 38/50, Training Loss: 1.4223, Validation Loss: 1.7513, Training Accuracy: 41.52%, Validation Accuracy: 31.28%\n",
      "Epoch 39/50, Training Loss: 1.4042, Validation Loss: 1.9263, Training Accuracy: 41.92%, Validation Accuracy: 30.78%\n",
      "Epoch 40/50, Training Loss: 1.4192, Validation Loss: 1.7131, Training Accuracy: 41.71%, Validation Accuracy: 34.43%\n",
      "Epoch 41/50, Training Loss: 1.4233, Validation Loss: 1.5855, Training Accuracy: 41.64%, Validation Accuracy: 37.19%\n",
      "Epoch 42/50, Training Loss: 1.3665, Validation Loss: 1.5723, Training Accuracy: 42.97%, Validation Accuracy: 37.54%\n",
      "Epoch 43/50, Training Loss: 1.3612, Validation Loss: 1.6408, Training Accuracy: 42.86%, Validation Accuracy: 36.59%\n",
      "Epoch 44/50, Training Loss: 1.3411, Validation Loss: 1.5286, Training Accuracy: 44.14%, Validation Accuracy: 40.94%\n",
      "Epoch 45/50, Training Loss: 1.3502, Validation Loss: 1.5621, Training Accuracy: 44.50%, Validation Accuracy: 36.54%\n",
      "Epoch 46/50, Training Loss: 1.2888, Validation Loss: 1.5695, Training Accuracy: 46.15%, Validation Accuracy: 36.24%\n",
      "Epoch 47/50, Training Loss: 1.3119, Validation Loss: 1.5089, Training Accuracy: 45.61%, Validation Accuracy: 39.99%\n",
      "Epoch 48/50, Training Loss: 1.2604, Validation Loss: 1.5494, Training Accuracy: 47.85%, Validation Accuracy: 39.69%\n",
      "Epoch 49/50, Training Loss: 1.2625, Validation Loss: 1.4658, Training Accuracy: 47.78%, Validation Accuracy: 40.04%\n",
      "Epoch 50/50, Training Loss: 1.2515, Validation Loss: 1.5001, Training Accuracy: 48.27%, Validation Accuracy: 39.14%\n"
     ]
    }
   ],
   "source": [
    "# Call training function\n",
    "traintest.train_model(model, train_loader, val_loader,criterion,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb145407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb145407",
    "outputId": "0c402735-9dec-46c1-f33c-b50613db5f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 40.16%\n"
     ]
    }
   ],
   "source": [
    "traintest.evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K1TvkMH4cf_E",
   "metadata": {
    "id": "K1TvkMH4cf_E"
   },
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "torch.save(model.state_dict(), 'EEGEncoder_state_dict.pth')  # Save only the state dict\n",
    "torch.save(model, 'EEGEncoder.pth')  # Save the entire model\n",
    "torch.save(optimizer.state_dict(), 'optimizer_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ybYD57mfMak",
   "metadata": {
    "id": "6ybYD57mfMak"
   },
   "source": [
    "##Further Training to be done on a new segment of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z0dkDWaffLZJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0dkDWaffLZJ",
    "outputId": "d6467c72-a544-4f48-ab81-69c684cc1a25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-909b9687f119>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset=torch.load(r\"/content/drive/MyDrive/Data/eeg_14_70_std.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset', 'labels', 'images'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=torch.load(r\"/content/drive/MyDrive/Data/eeg_14_70_std.pth\")\n",
    "labels=dataset['labels']\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rFyaYjPhha07",
   "metadata": {
    "id": "rFyaYjPhha07"
   },
   "outputs": [],
   "source": [
    "data=dataset['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v_D1ilyjhb7h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_D1ilyjhb7h",
    "outputId": "34e6f644-e1c5-4e36-99bf-b1a747143aea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-02f78271f0ac>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  splits=torch.load(r\"/content/drive/MyDrive/Data/block_splits_by_image_all.pth\")\n"
     ]
    }
   ],
   "source": [
    "splits=torch.load(r\"/content/drive/MyDrive/Data/block_splits_by_image_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q_UqhLCthclM",
   "metadata": {
    "id": "q_UqhLCthclM"
   },
   "outputs": [],
   "source": [
    "x_train,x_val,x_test,y_train,y_val,y_test=traintest.Splitter(dataset,splits,subject_no=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DcIILcB2hcbm",
   "metadata": {
    "id": "DcIILcB2hcbm"
   },
   "outputs": [],
   "source": [
    "x_train=torch.stack(x_train)\n",
    "#x_train=x_train.unsqueeze(3)\n",
    "x_val=torch.stack(x_val)\n",
    "#x_val=x_val.unsqueeze(3)\n",
    "x_test=torch.stack(x_test)\n",
    "#x_test=x_test.unsqueeze(3)\n",
    "y_train=torch.tensor(y_train)\n",
    "y_val=torch.tensor(y_val)\n",
    "y_test=torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EOu61X9qmJOf",
   "metadata": {
    "id": "EOu61X9qmJOf"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val,y_val)\n",
    "test_dataset = TensorDataset(x_test,y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xocMo07xiLPK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xocMo07xiLPK",
    "outputId": "799dfed0-fa6b-44a0-cb40-c098c6905db7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-148cb984ddee>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('/content/drive/MyDrive/New Approach/EEGEncoder.pth')\n",
      "<ipython-input-17-148cb984ddee>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/content/drive/MyDrive/New Approach/EEGEncoder_state_dict.pth'))\n",
      "<ipython-input-17-148cb984ddee>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load('/content/drive/MyDrive/New Approach/optimizer_state_dict.pth'))\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/content/drive/MyDrive/New Approach/EEGEncoder.pth')\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/New Approach/EEGEncoder_state_dict.pth'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "optimizer.load_state_dict(torch.load('/content/drive/MyDrive/New Approach/optimizer_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6pt-a_NEl9D6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pt-a_NEl9D6",
    "outputId": "f34e372c-215a-45f3-de4b-2005af051b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 2.0205, Validation Loss: 1.9329, Training Accuracy: 25.53%, Validation Accuracy: 25.88%\n",
      "Epoch 2/50, Training Loss: 1.8511, Validation Loss: 1.8485, Training Accuracy: 29.55%, Validation Accuracy: 29.68%\n",
      "Epoch 3/50, Training Loss: 1.7358, Validation Loss: 1.7577, Training Accuracy: 32.18%, Validation Accuracy: 31.68%\n",
      "Epoch 4/50, Training Loss: 1.6776, Validation Loss: 1.8013, Training Accuracy: 34.20%, Validation Accuracy: 27.88%\n",
      "Epoch 5/50, Training Loss: 1.6362, Validation Loss: 1.7587, Training Accuracy: 35.40%, Validation Accuracy: 29.98%\n",
      "Epoch 6/50, Training Loss: 1.5866, Validation Loss: 1.6811, Training Accuracy: 35.76%, Validation Accuracy: 34.13%\n",
      "Epoch 7/50, Training Loss: 1.5709, Validation Loss: 1.7480, Training Accuracy: 36.30%, Validation Accuracy: 33.48%\n",
      "Epoch 8/50, Training Loss: 1.5314, Validation Loss: 1.6965, Training Accuracy: 37.69%, Validation Accuracy: 32.63%\n",
      "Epoch 9/50, Training Loss: 1.5070, Validation Loss: 1.6625, Training Accuracy: 39.06%, Validation Accuracy: 32.13%\n",
      "Epoch 10/50, Training Loss: 1.4654, Validation Loss: 1.7823, Training Accuracy: 40.64%, Validation Accuracy: 30.28%\n",
      "Epoch 11/50, Training Loss: 1.4433, Validation Loss: 1.7009, Training Accuracy: 41.49%, Validation Accuracy: 33.78%\n",
      "Epoch 12/50, Training Loss: 1.4651, Validation Loss: 1.6532, Training Accuracy: 41.04%, Validation Accuracy: 33.98%\n",
      "Epoch 13/50, Training Loss: 1.4202, Validation Loss: 1.8914, Training Accuracy: 41.79%, Validation Accuracy: 29.68%\n",
      "Epoch 14/50, Training Loss: 1.3750, Validation Loss: 1.6792, Training Accuracy: 43.83%, Validation Accuracy: 34.48%\n",
      "Epoch 15/50, Training Loss: 1.3564, Validation Loss: 1.5779, Training Accuracy: 44.84%, Validation Accuracy: 37.14%\n",
      "Epoch 16/50, Training Loss: 1.3265, Validation Loss: 1.6515, Training Accuracy: 45.52%, Validation Accuracy: 35.39%\n",
      "Epoch 17/50, Training Loss: 1.3493, Validation Loss: 1.6536, Training Accuracy: 45.06%, Validation Accuracy: 37.04%\n",
      "Epoch 18/50, Training Loss: 1.3148, Validation Loss: 1.6273, Training Accuracy: 46.42%, Validation Accuracy: 36.74%\n",
      "Epoch 19/50, Training Loss: 1.2846, Validation Loss: 1.7408, Training Accuracy: 46.91%, Validation Accuracy: 34.58%\n",
      "Epoch 20/50, Training Loss: 1.2875, Validation Loss: 1.7073, Training Accuracy: 46.88%, Validation Accuracy: 35.04%\n",
      "Epoch 21/50, Training Loss: 1.2606, Validation Loss: 1.6060, Training Accuracy: 48.02%, Validation Accuracy: 38.09%\n",
      "Epoch 22/50, Training Loss: 1.2475, Validation Loss: 1.8115, Training Accuracy: 49.52%, Validation Accuracy: 33.98%\n",
      "Epoch 23/50, Training Loss: 1.2072, Validation Loss: 1.7065, Training Accuracy: 50.29%, Validation Accuracy: 35.24%\n",
      "Epoch 24/50, Training Loss: 1.2260, Validation Loss: 1.7383, Training Accuracy: 50.04%, Validation Accuracy: 33.93%\n",
      "Epoch 25/50, Training Loss: 1.2180, Validation Loss: 1.6955, Training Accuracy: 50.45%, Validation Accuracy: 35.79%\n",
      "Epoch 26/50, Training Loss: 1.2283, Validation Loss: 1.6325, Training Accuracy: 51.43%, Validation Accuracy: 38.84%\n",
      "Epoch 27/50, Training Loss: 1.1960, Validation Loss: 1.7167, Training Accuracy: 52.06%, Validation Accuracy: 36.39%\n",
      "Epoch 28/50, Training Loss: 1.1458, Validation Loss: 1.7682, Training Accuracy: 53.71%, Validation Accuracy: 36.69%\n",
      "Epoch 29/50, Training Loss: 1.1362, Validation Loss: 1.6934, Training Accuracy: 53.64%, Validation Accuracy: 38.84%\n",
      "Epoch 30/50, Training Loss: 1.1371, Validation Loss: 1.6195, Training Accuracy: 54.13%, Validation Accuracy: 38.44%\n",
      "Epoch 31/50, Training Loss: 1.1532, Validation Loss: 1.6380, Training Accuracy: 53.10%, Validation Accuracy: 39.49%\n",
      "Epoch 32/50, Training Loss: 1.0917, Validation Loss: 1.7115, Training Accuracy: 56.51%, Validation Accuracy: 37.09%\n",
      "Epoch 33/50, Training Loss: 1.0788, Validation Loss: 1.6765, Training Accuracy: 56.30%, Validation Accuracy: 40.19%\n",
      "Epoch 34/50, Training Loss: 1.0816, Validation Loss: 1.6999, Training Accuracy: 56.09%, Validation Accuracy: 40.44%\n",
      "Epoch 35/50, Training Loss: 1.0595, Validation Loss: 1.8214, Training Accuracy: 57.48%, Validation Accuracy: 34.98%\n",
      "Epoch 36/50, Training Loss: 1.0522, Validation Loss: 1.6657, Training Accuracy: 57.70%, Validation Accuracy: 39.54%\n",
      "Epoch 37/50, Training Loss: 1.0471, Validation Loss: 1.7348, Training Accuracy: 59.01%, Validation Accuracy: 38.29%\n",
      "Epoch 38/50, Training Loss: 1.0151, Validation Loss: 1.7582, Training Accuracy: 58.49%, Validation Accuracy: 37.74%\n",
      "Epoch 39/50, Training Loss: 1.0155, Validation Loss: 1.6575, Training Accuracy: 58.71%, Validation Accuracy: 41.74%\n",
      "Epoch 40/50, Training Loss: 1.0042, Validation Loss: 1.7528, Training Accuracy: 59.81%, Validation Accuracy: 37.39%\n",
      "Epoch 41/50, Training Loss: 1.0011, Validation Loss: 1.8420, Training Accuracy: 59.90%, Validation Accuracy: 37.29%\n",
      "Epoch 42/50, Training Loss: 0.9799, Validation Loss: 1.7743, Training Accuracy: 60.50%, Validation Accuracy: 38.44%\n",
      "Epoch 43/50, Training Loss: 0.9699, Validation Loss: 1.7783, Training Accuracy: 61.23%, Validation Accuracy: 39.39%\n",
      "Epoch 44/50, Training Loss: 0.9862, Validation Loss: 1.9173, Training Accuracy: 60.95%, Validation Accuracy: 36.79%\n",
      "Epoch 45/50, Training Loss: 0.9773, Validation Loss: 1.7825, Training Accuracy: 60.40%, Validation Accuracy: 38.24%\n",
      "Epoch 46/50, Training Loss: 0.9214, Validation Loss: 1.8060, Training Accuracy: 63.14%, Validation Accuracy: 39.44%\n",
      "Epoch 47/50, Training Loss: 0.9540, Validation Loss: 1.7882, Training Accuracy: 61.73%, Validation Accuracy: 38.24%\n",
      "Epoch 48/50, Training Loss: 0.9423, Validation Loss: 1.8451, Training Accuracy: 62.91%, Validation Accuracy: 36.39%\n",
      "Epoch 49/50, Training Loss: 0.9091, Validation Loss: 1.7312, Training Accuracy: 63.96%, Validation Accuracy: 42.24%\n",
      "Epoch 50/50, Training Loss: 0.8960, Validation Loss: 2.0357, Training Accuracy: 64.72%, Validation Accuracy: 36.24%\n"
     ]
    }
   ],
   "source": [
    "traintest.train_model(model, train_loader, val_loader,criterion,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mpML698RvClW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpML698RvClW",
    "outputId": "38a4f7ba-f15d-49fa-8052-1422803b31c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 36.50%\n"
     ]
    }
   ],
   "source": [
    "traintest.evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wGbVivhAyEhQ",
   "metadata": {
    "id": "wGbVivhAyEhQ"
   },
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "torch.save(model.state_dict(), 'EEGEncoder_state_dict2.pth')  # Save only the state dict\n",
    "torch.save(model, 'EEGEncoder2.pth')  # Save the entire model\n",
    "torch.save(optimizer.state_dict(), 'optimizer_state_dict2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GcUh4qrydmSe",
   "metadata": {
    "id": "GcUh4qrydmSe"
   },
   "source": [
    "## Not Relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52a13e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb52a13e",
    "outputId": "51507c19-f804-492e-e784-d4b42111f53c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Given groups=1, weight of size [64, 40, 3], expected input[16, 128, 440] to have 40 channels, but got 128 channels instead\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(16, 128, 440)  # Create a sample input tensor\n",
    "\n",
    "# Initialize your model\n",
    "num_classes = 40  # Adjust based on the number of classes in your task\n",
    "model =EncoderEEG.EEGEncoder(num_classes)  # Use the correct model name here\n",
    "\n",
    "# Pass the sample input through the model\n",
    "try:\n",
    "    output = model(sample_input)\n",
    "    print(\"Output shape:\", output.shape)  # Print the output shape\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87491061",
   "metadata": {
    "id": "87491061",
    "outputId": "8e5659d6-dfeb-4431-c780-294dd83dceb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of EEGEncoder(\n",
      "  (temporal_block): TemporalBlock(\n",
      "    (network): Sequential(\n",
      "      (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(3,))\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(6,), dilation=(2,))\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(12,), dilation=(4,))\n",
      "      (5): ReLU()\n",
      "      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(24,), dilation=(8,))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (spatial_block): SpatialBlock(\n",
      "    (network): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (res_blocks): ModuleList(\n",
      "    (0-1): 2 x ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=32, out_features=40, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe285fb4",
   "metadata": {
    "id": "fe285fb4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
