{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dcdc03d-e043-4883-a262-1544c2f22a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('models')\n",
    "sys.path.append('instances_&_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5288830e-8e68-4c8f-a375-c0ea9546fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import EncoderEEG\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734784cd-4650-4e44-a0b9-81285e0ee831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fd68f7-5fbe-40bf-b11e-92cc37602466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02389026', 'n03888257', 'n03584829', 'n02607072', 'n03297495', 'n03063599', 'n03792782', 'n04086273', 'n02510455', 'n11939491', 'n02951358', 'n02281787', 'n02106662', 'n04120489', 'n03590841', 'n02992529', 'n03445777', 'n03180011', 'n02906734', 'n07873807', 'n03773504', 'n02492035', 'n03982430', 'n03709823', 'n03100240', 'n03376595', 'n03877472', 'n03775071', 'n03272010', 'n04069434', 'n03452741', 'n03792972', 'n07753592', 'n13054560', 'n03197337', 'n02504458', 'n02690373', 'n03272562', 'n04044716', 'n02124075']\n"
     ]
    }
   ],
   "source": [
    "dataset=torch.load(r\"C:\\Users\\hp\\Desktop\\M.Tech\\ML\\ML_Project\\Project Dataset\\eeg_signals_raw_with_mean_std.pth\")\n",
    "labels=dataset['labels']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfeba2db-3c71-4922-96f6-72779253aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11965"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=dataset['dataset']\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67d1df3-3279-42ac-ae99-5914344100d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data(data,subject_no=0):\n",
    "    if subject_no!=0:\n",
    "        x=[data[i]['eeg'][:,20:460] for i in range(len(data)) if data[i]['subject']==subject_no]\n",
    "        \n",
    "        y=[data[i]['label'] for i in range(len(data)) if data[i]['subject']==subject_no]\n",
    "    \n",
    "    else:\n",
    "        x=[data[i]['eeg'][:,20:460] for i in range(len(data))]\n",
    "\n",
    "        \n",
    "        y=[data[i]['label'] for i in range(len(data))]\n",
    "\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028a07d3-00d5-49d0-8f84-71964dee293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tensor shape: torch.Size([11965, 128, 440])\n",
      "y_tensor shape: torch.Size([11965])\n"
     ]
    }
   ],
   "source": [
    "x,y=Data(data,subject_no=0)\n",
    "# Ensure that x and y are lists of tensors\n",
    "x = [torch.tensor(item, dtype=torch.float32) if not isinstance(item, torch.Tensor) else item for item in x]\n",
    "y = [torch.tensor(item, dtype=torch.long) if not isinstance(item, torch.Tensor) else item for item in y]\n",
    "\n",
    "# Stack the tensors\n",
    "x_tensor = torch.stack(x)\n",
    "y_tensor = torch.stack(y)\n",
    "\n",
    "print(f\"x_tensor shape: {x_tensor.shape}\")\n",
    "print(f\"y_tensor shape: {y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dad68b4-bf74-4dd0-9220-72e1d6a7128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(r'C:\\Users\\hp\\Desktop\\M.Tech\\ML\\ML_Project\\ML_Project-main\\instances_&_dict\\EEGEncoder.pth')\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb3ac87-f71e-4858-a4a8-b5b31334a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1 - Type of x: <class 'list'>, Shape of x: 1985, Type of y: <class 'list'>, Shape of y: 1985\n",
      "Subject 1 - x_tensor shape: torch.Size([1985, 128, 440])\n",
      "Subject 1 - y_tensor shape: torch.Size([1985])\n",
      "Subject 2 - Type of x: <class 'list'>, Shape of x: 1996, Type of y: <class 'list'>, Shape of y: 1996\n",
      "Subject 2 - x_tensor shape: torch.Size([1996, 128, 440])\n",
      "Subject 2 - y_tensor shape: torch.Size([1996])\n",
      "Subject 3 - Type of x: <class 'list'>, Shape of x: 1996, Type of y: <class 'list'>, Shape of y: 1996\n",
      "Subject 3 - x_tensor shape: torch.Size([1996, 128, 440])\n",
      "Subject 3 - y_tensor shape: torch.Size([1996])\n",
      "Subject 4 - Type of x: <class 'list'>, Shape of x: 1996, Type of y: <class 'list'>, Shape of y: 1996\n",
      "Subject 4 - x_tensor shape: torch.Size([1996, 128, 440])\n",
      "Subject 4 - y_tensor shape: torch.Size([1996])\n",
      "Subject 5 - Type of x: <class 'list'>, Shape of x: 1996, Type of y: <class 'list'>, Shape of y: 1996\n",
      "Subject 5 - x_tensor shape: torch.Size([1996, 128, 440])\n",
      "Subject 5 - y_tensor shape: torch.Size([1996])\n",
      "Subject 6 - Type of x: <class 'list'>, Shape of x: 1996, Type of y: <class 'list'>, Shape of y: 1996\n",
      "Subject 6 - x_tensor shape: torch.Size([1996, 128, 440])\n",
      "Subject 6 - y_tensor shape: torch.Size([1996])\n"
     ]
    }
   ],
   "source": [
    "subject_data = {}\n",
    "\n",
    "# Iterate through each subject (1 to 6)\n",
    "for subject_no in range(1, 7):\n",
    "    x, y = Data(data, subject_no=subject_no)  # Get EEG data and labels for the subject\n",
    "    # Debugging step: Check the type and shape of x and y\n",
    "    print(f\"Subject {subject_no} - Type of x: {type(x)}, Shape of x: {len(x)}, Type of y: {type(y)}, Shape of y: {len(y)}\")\n",
    "    \n",
    "    # If x is a list of tensors (e.g., list of EEG data arrays), stack them\n",
    "    x = [torch.tensor(item, dtype=torch.float32) if not isinstance(item, torch.Tensor) else item for item in x]\n",
    "    y = [torch.tensor(item, dtype=torch.long) if not isinstance(item, torch.Tensor) else item for item in y]\n",
    "\n",
    "    # Stack the tensors\n",
    "    x_tensor = torch.stack(x)\n",
    "    y_tensor = torch.stack(y) # Assuming classification task, use long for labels\n",
    "\n",
    "    x_tensor = x_tensor.to(device)  # Move input tensor to the same device (GPU)\n",
    "    y_tensor = y_tensor.to(device)  \n",
    "    # Check if x_tensor is of the correct shape\n",
    "    print(f\"Subject {subject_no} - x_tensor shape: {x_tensor.shape}\")\n",
    "    print(f\"Subject {subject_no} - y_tensor shape: {y_tensor.shape}\")\n",
    "\n",
    "    # Create a DataLoader for batching (if needed)\n",
    "    dataset = TensorDataset(x_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Disable gradients since we are not training the model\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            # Forward pass through the model\n",
    "            output, embeddings = model(batch_x)  # This gives the model's output (e.g., logits, embeddings)\n",
    "            all_embeddings.append(embeddings)  # Save the output for each batch\n",
    "    \n",
    "    # Concatenate all the outputs into a single tensor (for the entire subject)\n",
    "    subject_output = torch.cat(all_embeddings, dim=0)  # Concatenate along batch dimension\n",
    "    \n",
    "    # Save EEG data, labels, and model output (embeddings) for the subject\n",
    "    subject_data[subject_no] = {\n",
    "        'EEG': x_tensor,\n",
    "        'Labels': y_tensor,\n",
    "        'z': subject_output  # Store the output (e.g., embeddings, logits, etc.)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81cd202-1ce0-4a6e-bb4a-2a9f9f24564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(subject_data,'data_with_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8496336f-f712-4c1f-9ec1-2ef43998b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_GAN = torch.load('data_with_embeddings.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd001e83-beab-4a0c-a7cc-d945d7940976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5167, -0.3976, -0.0349,  ..., -0.8051,  0.5117, -0.7190],\n",
       "        [ 1.3497, -0.1515, -0.0863,  ..., -0.9664, -1.3735,  0.4914],\n",
       "        [ 0.4486,  0.1777, -0.7065,  ...,  0.1288, -0.2138,  0.5208],\n",
       "        ...,\n",
       "        [-0.2847,  0.0429,  0.2183,  ...,  0.6406,  0.1834, -0.1103],\n",
       "        [ 1.1469, -0.3220,  0.2021,  ..., -2.3834, -1.2500,  0.1670],\n",
       "        [-0.2633, -0.1413, -0.9956,  ...,  0.6392,  0.5316,  0.0058]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_GAN[1]['z']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
