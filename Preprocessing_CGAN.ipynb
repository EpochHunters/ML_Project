{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWaUgYkxpIZR"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYrSMF1GpJMe"
   },
   "source": [
    "## Using 14-70 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDlGYv9NoSY0"
   },
   "outputs": [],
   "source": [
    "eeg_data_path = \"/content/drive/MyDrive/Data/eeg_14_70_std.pth\"\n",
    "eeg_data = torch.load(eeg_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37d7AT1eqir4"
   },
   "outputs": [],
   "source": [
    "#### Don't re- run\n",
    "input_dir = \"/content/drive/MyDrive/Data/Subset\"\n",
    "output_dir = \"/content/drive/MyDrive/Data/Subset_128x128\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def preprocess_images(input_dir, output_dir, size=(128, 128)):\n",
    "    for folder_name in os.listdir(input_dir):\n",
    "        input_folder_path = os.path.join(input_dir, folder_name)\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)  # Create output subfolder\n",
    "\n",
    "        for file_name in os.listdir(input_folder_path):\n",
    "            input_file_path = os.path.join(input_folder_path, file_name)\n",
    "            output_file_path = os.path.join(output_folder_path, file_name)\n",
    "\n",
    "            # Open, resize, and save the image\n",
    "            with Image.open(input_file_path) as img:\n",
    "                img = img.convert(\"RGB\")  # Ensure consistent format\n",
    "                img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "                img.save(output_file_path)\n",
    "\n",
    "    print(f\"All images resized to {size} and saved in {output_dir}\")\n",
    "\n",
    "# Run preprocessing\n",
    "preprocess_images(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qamsNZ77sAHs"
   },
   "outputs": [],
   "source": [
    "### DONT RE-run\n",
    "\n",
    "eeg_data_path = \"/content/drive/MyDrive/Data/eeg_14_70_std.pth\"\n",
    "eeg_data = torch.load(eeg_data_path)\n",
    "\n",
    "def preprocess_eeg_signals(eeg_data):\n",
    "    for entry in eeg_data['dataset']:\n",
    "        # Get the EEG tensor and trim it\n",
    "        eeg_signal = entry['eeg']  # Shape: [128, 500]\n",
    "        entry['eeg'] = eeg_signal[:, 20:-40]  # Trim to [128, 440]\n",
    "\n",
    "    print(\"EEG signals preprocessed to shape [128, 440]\")\n",
    "    return eeg_data\n",
    "\n",
    "# Preprocess EEG\n",
    "eeg_data_preprocessed = preprocess_eeg_signals(eeg_data)\n",
    "\n",
    "# Save the preprocessed EEG data\n",
    "preprocessed_path = \"/content/drive/MyDrive/Data/eeg_14_70_preprocessed.pth\"\n",
    "torch.save(eeg_data_preprocessed, preprocessed_path)\n",
    "print(f\"Preprocessed EEG data saved at {preprocessed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlDSYbhHz1Bq"
   },
   "outputs": [],
   "source": [
    "input_dir = \"/content/drive/MyDrive/Data/Subset\"\n",
    "output_dir = \"/content/drive/MyDrive/Data/Subset_128x128\"\n",
    "preprocessed_path = \"/content/drive/MyDrive/Data/eeg_14_70_preprocessed.pth\"\n",
    "eeg_data_preprocessed = torch.load(preprocessed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAzwk0pWtcF4"
   },
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    # Convert to numpy array and normalize to [-1, 1]\n",
    "    img = np.array(img) / 127.5 - 1  # Rescale to [-1, 1]\n",
    "    return img\n",
    "\n",
    "def preprocess_images_with_normalization(input_dir, output_dir, size=(128, 128)):\n",
    "    for folder_name in os.listdir(input_dir):\n",
    "        input_folder_path = os.path.join(input_dir, folder_name)\n",
    "        output_folder_path = os.path.join(output_dir, folder_name)\n",
    "        os.makedirs(output_folder_path, exist_ok=True)  # Create output subfolder\n",
    "\n",
    "        for file_name in os.listdir(input_folder_path):\n",
    "            input_file_path = os.path.join(input_folder_path, file_name)\n",
    "            output_file_path = os.path.join(output_folder_path, file_name)\n",
    "\n",
    "            # Open, resize, normalize, and save the image\n",
    "            with Image.open(input_file_path) as img:\n",
    "                img = img.convert(\"RGB\")  # Ensure consistent format\n",
    "                img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "                img = normalize_image(img)\n",
    "\n",
    "                # Convert back to image and save\n",
    "                img = Image.fromarray(np.uint8((img + 1) * 127.5))  # Denormalize for saving\n",
    "                img.save(output_file_path)\n",
    "\n",
    "    print(f\"All images resized and normalized to {size} and saved in {output_dir}\")\n",
    "\n",
    "# Run image preprocessing with normalization\n",
    "preprocess_images_with_normalization(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9medpj_zGcc"
   },
   "outputs": [],
   "source": [
    "def normalize_eeg_signal(eeg_signal):\n",
    "    # Normalize to zero mean and unit variance\n",
    "    return (eeg_signal - eeg_signal.mean()) / eeg_signal.std()\n",
    "\n",
    "def preprocess_eeg_signals_with_normalization(eeg_data):\n",
    "    for entry in eeg_data['dataset']:\n",
    "        # Get the EEG signal and normalize it\n",
    "        eeg_signal = entry['eeg']  # Shape: [128, 440]\n",
    "        entry['eeg'] = normalize_eeg_signal(eeg_signal)\n",
    "\n",
    "    print(\"EEG signals normalized to zero mean and unit variance\")\n",
    "    return eeg_data\n",
    "\n",
    "# Preprocess EEG with normalization\n",
    "eeg_data_normalized = preprocess_eeg_signals_with_normalization(eeg_data)\n",
    "\n",
    "# Save the preprocessed EEG data\n",
    "preprocessed_path = \"/content/drive/MyDrive/Data/eeg_14_70_normalized.pth\"\n",
    "torch.save(eeg_data_normalized, preprocessed_path)\n",
    "print(f\"Preprocessed EEG data saved at {preprocessed_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6ViXUm3aYkj"
   },
   "outputs": [],
   "source": [
    "eeg_data_normalized = torch.load(\"/content/drive/MyDrive/Data/eeg_14_70_normalized.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVrehIGmbHfy"
   },
   "outputs": [],
   "source": [
    "eeg_data_normalized['dataset'][0]['eeg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eE7lGKcQzKt9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm  # Import for spectral normalization\n",
    "\n",
    "# Define ResBlock with Spectral Normalization\n",
    "# class ResBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, downsample=False):\n",
    "#         super(ResBlock, self).__init__()\n",
    "\n",
    "#         # Convolution layers\n",
    "#         self.conv1 = spectral_norm(nn.Conv2d(in_channels, out_channels, 3, padding=1))\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.conv2 = spectral_norm(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "#         # Downsampling or upsampling\n",
    "#         self.downsample = nn.Conv2d(in_channels, out_channels, 1, stride=2, padding=0) if downsample else None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.bn2(self.conv2(x))\n",
    "\n",
    "#         # If downsample is needed (for reducing the spatial dimension)\n",
    "#         if self.downsample:\n",
    "#             residual = self.downsample(residual)\n",
    "\n",
    "#         x += residual  # Add the residual connection\n",
    "        # return F.relu(x)\n",
    "\n",
    "# Generator model with Spectral Normalization\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, y_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Input: z + y\n",
    "        self.input_dim = z_dim + y_dim\n",
    "\n",
    "        # Dense layer\n",
    "        self.dense = nn.Linear(self.input_dim, 4 * 4 * 1024)\n",
    "\n",
    "        # ResBlocks for upsampling\n",
    "        self.resblock1 = ResBlock(1024, 1024)\n",
    "        self.resblock2 = ResBlock(1024, 512)\n",
    "        self.resblock3 = ResBlock(512, 256)\n",
    "        self.resblock4 = ResBlock(256, 128)\n",
    "        self.resblock5 = ResBlock(128, 64)\n",
    "\n",
    "        # Final convolution to produce an image of shape (3, 128, 128)\n",
    "        self.conv = spectral_norm(nn.Conv2d(64, 3, 3, padding=1))\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        # Concatenate noise vector z and conditional vector y\n",
    "        x = torch.cat([z, y], dim=1)\n",
    "\n",
    "        # Pass through the dense layer\n",
    "        x = self.dense(x)\n",
    "        x = x.view(-1, 1024, 4, 4)  # Reshape to (batch, 1024, 4, 4)\n",
    "\n",
    "        # Apply ResBlocks for upsampling\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.resblock5(x)\n",
    "\n",
    "        # Final convolution and Tanh activation\n",
    "        x = self.conv(x)\n",
    "        x = self.tanh(x)  # Output image range [-1, 1]\n",
    "        return x\n",
    "\n",
    "# Discriminator model with Spectral Normalization\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        # Apply spectral normalization directly to convolution layers\n",
    "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, out_channels, 3, padding=1))\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Downsampling or upsampling (if required)\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        # If downsampling is needed (for reducing spatial dimensions)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "\n",
    "        x += residual  # Add residual connection\n",
    "        return F.relu(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, y_dim=128):\n",
    "        super().__init__()  # Corrected the super call\n",
    "\n",
    "        # ResBlocks with spectral normalization applied within the blocks\n",
    "        self.resblock1 = ResBlock(3, 64)  # Input: 3 channels (RGB), output: 64 channels\n",
    "        self.resblock2 = ResBlock(64, 128)\n",
    "        self.resblock3 = ResBlock(128, 256)\n",
    "        self.resblock4 = ResBlock(256, 512)\n",
    "\n",
    "        # Conditional embedding layer for labels\n",
    "        self.embed = nn.Embedding(y_dim, 1024)\n",
    "\n",
    "        # Final fully connected layer to output probability\n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Pass image through ResBlocks\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "\n",
    "        # Flatten image tensor and embed the conditional label vector y\n",
    "        y_embedded = self.embed(y)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image\n",
    "        x = torch.cat([x, y_embedded], dim=1)  # Concatenate with the conditional label vector\n",
    "\n",
    "        # Final fully connected layer to get probability\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2pPR3Djzgps"
   },
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "def discriminator_loss(D_real, D_fake, epsilon=1e-8):\n",
    "    real_loss = torch.mean(torch.log(D_real + epsilon))\n",
    "    fake_loss = torch.mean(torch.log(1 - D_fake + epsilon))\n",
    "    return -(real_loss + fake_loss)\n",
    "\n",
    "# Generator loss\n",
    "def generator_loss(D_fake, epsilon=1e-8):\n",
    "    return -torch.mean(torch.log(D_fake + epsilon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvTtraTezif2"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kRICIIM02Wi"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to the folder containing the 40 class subfolders\n",
    "# input_dir = \"/content/drive/MyDrive/Data/Subset_128x128\"\n",
    "\n",
    "# # List to store filename and corresponding label\n",
    "# data = []\n",
    "\n",
    "# # Loop through each class folder (0-39)\n",
    "# for label, folder_name in enumerate(os.listdir(input_dir)):\n",
    "#     folder_path = os.path.join(input_dir, folder_name)\n",
    "\n",
    "#     # Skip non-directory files\n",
    "#     if not os.path.isdir(folder_path):\n",
    "#         continue\n",
    "\n",
    "#     # Loop through each image in the folder\n",
    "#     for image_name in os.listdir(folder_path):\n",
    "#         if image_name.endswith(\".JPEG\"):\n",
    "#             data.append([image_name, label])\n",
    "\n",
    "# # Convert the list into a pandas DataFrame\n",
    "# df = pd.DataFrame(data, columns=[\"filename\", \"label\"])\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# labels_csv_path = \"/content/drive/MyDrive/Data/labels.csv\"\n",
    "# df.to_csv(labels_csv_path, index=False)\n",
    "\n",
    "# print(f\"Labels CSV created at {labels_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-fWhbeQ0Nv3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        # Read the CSV file and make sure there is no header or extra unwanted characters\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "\n",
    "        # Make sure to drop any rows that might have non-numeric labels (if any)\n",
    "        self.data_frame['label'] = pd.to_numeric(self.data_frame['label'], errors='coerce')\n",
    "\n",
    "        # Remove any rows where the label conversion failed (if any)\n",
    "        self.data_frame = self.data_frame.dropna(subset=['label'])\n",
    "\n",
    "        # Ensure that label column is in integer format\n",
    "        self.data_frame['label'] = self.data_frame['label'].astype(int)\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the synset ID for the image and construct the path correctly\n",
    "        label = self.data_frame.iloc[idx, 1]\n",
    "        img_name = self.data_frame.iloc[idx, 0]  # This should give the full filename, e.g., 'n03180011_1108.JPEG'\n",
    "\n",
    "        # Extract the subfolder name from the filename (e.g., 'n03180011')\n",
    "        subfolder_name = img_name.split('_')[0]\n",
    "\n",
    "        # Construct the full image path by joining the subfolder and filename\n",
    "        img_path = os.path.join(self.img_dir, subfolder_name, img_name)\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define dataset and dataloader\n",
    "image_dir = \"/content/drive/MyDrive/Data/Subset_128x128\"\n",
    "label_csv = \"/content/drive/MyDrive/Data/labels.csv\"\n",
    "dataset = ImageDataset(label_csv, image_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUwKzPH82soG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "\n",
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "z_dim = 100  # Size of noise vector\n",
    "y_dim = 128  # Number of classes\n",
    "generator = Generator(z_dim=z_dim, y_dim=y_dim).to(device)\n",
    "discriminator = Discriminator(y_dim=y_dim).to(device)\n",
    "\n",
    "# Optimizers for Generator and Discriminator\n",
    "lr = 0.0002\n",
    "beta1, beta2 = 0.5, 0.999\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 50\n",
    "sample_interval = 100  # Interval to save sample images\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, labels) in enumerate(dataloader):\n",
    "        # Move data to device\n",
    "        real_images = real_images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Create noise vector z\n",
    "        z = torch.randn(real_images.size(0), z_dim, device=device)  # Random noise\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Real images\n",
    "        D_real = discriminator(real_images, labels)\n",
    "        D_real_loss = discriminator_loss(D_real, torch.ones_like(D_real, device=device))\n",
    "\n",
    "        # Fake images\n",
    "        fake_images = generator(z, labels)\n",
    "        D_fake = discriminator(fake_images.detach(), labels)\n",
    "        D_fake_loss = discriminator_loss(D_fake, torch.zeros_like(D_fake, device=device))\n",
    "\n",
    "        # Total Discriminator loss and backpropagation\n",
    "        d_loss = D_real_loss + D_fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate fake images\n",
    "        D_fake = discriminator(fake_images, labels)\n",
    "\n",
    "        # Generator loss\n",
    "        g_loss = generator_loss(D_fake)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Print and save the losses at sample interval\n",
    "        if i % sample_interval == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')\n",
    "\n",
    "            # Save generated samples for visualization\n",
    "            with torch.no_grad():\n",
    "                sample_z = torch.randn(64, z_dim, device=device)  # Generate sample noise\n",
    "                sample_labels = torch.randint(0, y_dim, (64,), device=device)  # Random labels\n",
    "                samples = generator(sample_z, sample_labels)\n",
    "                samples = (samples + 1) / 2  # Scale back to [0, 1] for visualization\n",
    "                save_image(samples, f'./samples/epoch_{epoch}_step_{i}.png', nrow=8, normalize=True)\n",
    "\n",
    "    # Optional: Save model checkpoints every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')\n",
    "        torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p72fQhXJ7PKA"
   },
   "source": [
    "## Trying with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOrZGA875CHV"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMUbjffA6PEA"
   },
   "outputs": [],
   "source": [
    "# for i, (real_images, labels) in enumerate(dataloader):\n",
    "#     real_images = real_images.to(device)  # Move to CPU\n",
    "#     labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP8GYXMz62Zc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
