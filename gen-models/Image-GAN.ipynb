{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjWyAwM5Nf0K"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAPVflLFVplL",
    "outputId": "3d9f45ca-112f-4cd0-faa6-0235768b868b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WBsetAbPaMf"
   },
   "outputs": [],
   "source": [
    "image_dir = \"/content/drive/MyDrive/Subset_128x128\"\n",
    "labels_csv = \"/content/drive/MyDrive/labels.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 40 dimensinal Class Embedding Layer using nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVbjdRaIPcHU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, labels_csv, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_folder (str): Path to the main image folder.\n",
    "            labels_csv (str): Path to the labels CSV file with `filename` and `label` columns.\n",
    "            transform (callable, optional): Optional transform to be applied on the images.\n",
    "        \"\"\"\n",
    "        self.labels_df = pd.read_csv(labels_csv)  # Load the CSV\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        row = self.labels_df.iloc[idx]\n",
    "        filename = row[\"filename\"]  \n",
    "        label = row[\"label\"]        \n",
    "\n",
    "        # Build the full image path\n",
    "        synset_id = filename.split('_')[0] \n",
    "        image_path = os.path.join(self.image_folder, synset_id, filename)\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\"image\": image, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sx_OK_V5PvmD"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor(),        \n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "NhA8wiomPxXO",
    "outputId": "3c91019c-aad6-4b7d-ae58-1759946052d1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-004e028d5621>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m image_dataset = ImageDataset(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8dc1891e7398>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_folder, labels_csv, transform)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtransform\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/labels.csv'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "image_dataset = ImageDataset(\n",
    "    image_folder=image_dir,\n",
    "    labels_csv=labels_csv,\n",
    "    transform=image_transforms\n",
    ")\n",
    "\n",
    "\n",
    "data_loader = DataLoader(image_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "for batch in data_loader:\n",
    "    print(\"Image batch shape:\", batch[\"image\"].shape)  # Shape: (batch_size, 3, 128, 128)\n",
    "    print(\"Label batch shape:\", batch[\"label\"].shape)  # Shape: (batch_size,)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYcOVbN9QI14"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKS-g-dbP0Bl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, class_dim=40):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Linear(noise_dim + class_dim, 4 * 4 * 1024) \n",
    "        self.resblock1 = ResBlockUp(1024, 512)\n",
    "        self.resblock2 = ResBlockUp(512, 256)\n",
    "        self.resblock3 = ResBlockUp(256, 128)\n",
    "        self.resblock4 = ResBlockUp(128, 64)\n",
    "        self.conv = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "        self.tanh = nn.Tanh() \n",
    "\n",
    "    def forward(self, noise, class_embedding):\n",
    "        x = torch.cat([noise, class_embedding], dim=1)  \n",
    "        x = self.fc(x).view(-1, 1024, 4, 4) \n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.conv(x)\n",
    "        return self.tanh(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, class_dim=40):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.resblock1 = ResBlockDown(3, 64)\n",
    "        self.resblock2 = ResBlockDown(64, 128)\n",
    "        self.resblock3 = ResBlockDown(128, 256)\n",
    "        self.resblock4 = ResBlockDown(256, 512)\n",
    "        self.resblock5 = ResBlockDown(512, 1024)\n",
    "        self.resblock_final = ResBlockDown(1024, 1024)\n",
    "        self.global_sum_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "        # Conditional embedding\n",
    "        self.embed = nn.Linear(class_dim, 1024)\n",
    "\n",
    "    def forward(self, img, class_embedding):\n",
    "        x = self.resblock1(img)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "        x = self.resblock5(x)\n",
    "        x = self.resblock_final(x)\n",
    "        x = self.global_sum_pooling(x).view(x.size(0), -1)  \n",
    "\n",
    "        \n",
    "        condition_embed = self.embed(class_embedding)\n",
    "        x = x + condition_embed\n",
    "\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQPrYSjBQDpo"
   },
   "outputs": [],
   "source": [
    "class ResBlockUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlockUp, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),  \n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.upsample(x)  # Shortcut path\n",
    "        main_path = self.block(F.interpolate(x, scale_factor=2, mode='nearest'))  \n",
    "        return shortcut + main_path  # Combine paths\n",
    "class ResBlockDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlockDown, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.downsample(x)  \n",
    "        main_path = self.block(x)  \n",
    "        return shortcut + main_path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SONzsstJQe1X",
    "outputId": "0c90d76c-87ce-48b4-fcc0-3d4dd829e089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ms-le4cQa5A"
   },
   "outputs": [],
   "source": [
    "class_embedding_layer = nn.Embedding(num_embeddings=40, embedding_dim=40).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1PKdbhdQdJM"
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, data_loader, class_embedding_layer, num_epochs=20, noise_dim=100, lr=0.0002):\n",
    "   \n",
    "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "   \n",
    "    gan_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch in tqdm(data_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "           \n",
    "            optimizer_disc.zero_grad()\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "           \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels).detach() \n",
    "            fake_images = generator(noise, class_embeddings)\n",
    "\n",
    "           \n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            \n",
    "            real_loss = gan_loss_fn(discriminator(images, class_embeddings), real_labels)\n",
    "            fake_loss = gan_loss_fn(discriminator(fake_images.detach(), class_embeddings), fake_labels) \n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "           \n",
    "            optimizer_gen.zero_grad()\n",
    "\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels)  \n",
    "            fake_images = generator(noise, class_embeddings)\n",
    "\n",
    "            \n",
    "            gen_loss = gan_loss_fn(discriminator(fake_images, class_embeddings), real_labels)\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "      \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Gen Loss: {gen_loss.item():.4f} | Disc Loss: {disc_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2dQXLSwQ3X2"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zLXBm0BQxQU",
    "outputId": "92095467-d89e-4640-c978-d4ddb86805c3"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 125/125 [11:11<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] | Gen Loss: 8.7357 | Disc Loss: 0.0008\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 125/125 [00:25<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] | Gen Loss: 12.7393 | Disc Loss: 0.0001\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 125/125 [00:26<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] | Gen Loss: 13.0433 | Disc Loss: 0.0000\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 125/125 [00:26<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] | Gen Loss: 15.0665 | Disc Loss: 0.0000\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] | Gen Loss: 10.5754 | Disc Loss: 0.0001\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] | Gen Loss: 10.6108 | Disc Loss: 0.0000\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] | Gen Loss: 13.2657 | Disc Loss: 0.0000\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] | Gen Loss: 15.7211 | Disc Loss: 0.0000\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] | Gen Loss: 12.0073 | Disc Loss: 0.0000\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] | Gen Loss: 14.6445 | Disc Loss: 0.0000\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] | Gen Loss: 14.8837 | Disc Loss: 0.0000\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] | Gen Loss: 16.5090 | Disc Loss: 0.0000\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] | Gen Loss: 11.8534 | Disc Loss: 0.0000\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] | Gen Loss: 15.5641 | Disc Loss: 0.0000\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] | Gen Loss: 12.9573 | Disc Loss: 0.0000\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] | Gen Loss: 13.2635 | Disc Loss: 0.0000\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] | Gen Loss: 12.6693 | Disc Loss: 0.0000\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] | Gen Loss: 15.5099 | Disc Loss: 0.0000\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] | Gen Loss: 15.5695 | Disc Loss: 0.0000\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] | Gen Loss: 13.0028 | Disc Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]), \n",
    "])\n",
    "\n",
    "\n",
    "image_dataset = ImageDataset(image_folder=image_dir, labels_csv=labels_csv, transform=image_transforms)\n",
    "data_loader = DataLoader(image_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "noise_dim = 100\n",
    "class_dim = 40 \n",
    "lr = 0.0002\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "generator = Generator(noise_dim=noise_dim, class_dim=class_dim).to(device)\n",
    "discriminator = Discriminator(class_dim=class_dim).to(device)\n",
    "\n",
    "\n",
    "class_embedding_layer = nn.Embedding(num_embeddings=40, embedding_dim=40).to(device)\n",
    "\n",
    "\n",
    "train_gan(generator, discriminator, data_loader, class_embedding_layer, num_epochs=num_epochs, noise_dim=noise_dim, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le0Eo4JXZ_Za"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_gan(generator, discriminator, data_loader, class_embedding_layer, num_epochs=20, noise_dim=100, lr=0.0002):\n",
    "   \n",
    "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=lr * 0.5, betas=(0.5, 0.999)) \n",
    "\n",
    " \n",
    "    gan_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch in tqdm(data_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            \n",
    "            optimizer_disc.zero_grad()\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels).detach()\n",
    "            fake_images = generator(noise, class_embeddings)\n",
    "\n",
    "            \n",
    "            real_images_noisy = images + 0.05 * torch.randn_like(images).to(device)\n",
    "            fake_images_noisy = fake_images.detach() + 0.05 * torch.randn_like(fake_images).to(device)\n",
    "\n",
    "           \n",
    "            real_labels = torch.full((batch_size, 1), 0.9, device=device)\n",
    "            fake_labels = torch.full((batch_size, 1), 0.1, device=device)\n",
    "\n",
    "           \n",
    "            real_loss = gan_loss_fn(discriminator(real_images_noisy, class_embeddings), real_labels)\n",
    "            fake_loss = gan_loss_fn(discriminator(fake_images_noisy, class_embeddings), fake_labels)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            \n",
    "            optimizer_gen.zero_grad()\n",
    "\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels)\n",
    "            fake_images = generator(noise, class_embeddings)\n",
    "\n",
    "           \n",
    "            gen_loss = gan_loss_fn(discriminator(fake_images, class_embeddings), real_labels)\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Gen Loss: {gen_loss.item():.4f} | Disc Loss: {disc_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOXiDCDsa9FE",
    "outputId": "57530004-b6e2-41e9-e3de-5024b37ca57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | Gen Loss: 2.6183 | Disc Loss: 0.7053\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/100: 100%|██████████| 125/125 [00:26<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] | Gen Loss: 1.3555 | Disc Loss: 0.6533\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] | Gen Loss: 1.2990 | Disc Loss: 0.6526\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/100: 100%|██████████| 125/125 [00:26<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] | Gen Loss: 1.3306 | Disc Loss: 0.6573\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] | Gen Loss: 1.4664 | Disc Loss: 0.6509\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] | Gen Loss: 1.4197 | Disc Loss: 0.6506\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] | Gen Loss: 1.5017 | Disc Loss: 0.6538\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/100: 100%|██████████| 125/125 [00:26<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] | Gen Loss: 1.4377 | Disc Loss: 0.6516\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] | Gen Loss: 1.4889 | Disc Loss: 0.6515\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] | Gen Loss: 1.5996 | Disc Loss: 0.6524\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] | Gen Loss: 1.7390 | Disc Loss: 0.6511\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] | Gen Loss: 1.7061 | Disc Loss: 0.6510\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] | Gen Loss: 1.6137 | Disc Loss: 0.6518\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] | Gen Loss: 1.8054 | Disc Loss: 0.6509\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] | Gen Loss: 1.7214 | Disc Loss: 0.6507\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] | Gen Loss: 1.7758 | Disc Loss: 0.6508\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] | Gen Loss: 1.7699 | Disc Loss: 0.6504\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] | Gen Loss: 1.7707 | Disc Loss: 0.6507\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/100: 100%|██████████| 125/125 [00:26<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] | Gen Loss: 1.5890 | Disc Loss: 0.6502\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] | Gen Loss: 2.0868 | Disc Loss: 0.6561\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/100: 100%|██████████| 125/125 [00:27<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] | Gen Loss: 1.7256 | Disc Loss: 0.6502\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/100: 100%|██████████| 125/125 [00:26<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] | Gen Loss: 1.8084 | Disc Loss: 0.6504\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/100: 100%|██████████| 125/125 [00:26<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] | Gen Loss: 1.7699 | Disc Loss: 0.6505\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/100: 100%|██████████| 125/125 [00:28<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] | Gen Loss: 1.7116 | Disc Loss: 0.6539\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/100: 100%|██████████| 125/125 [00:27<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] | Gen Loss: 1.7967 | Disc Loss: 0.6503\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/100: 100%|██████████| 125/125 [00:26<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] | Gen Loss: 1.7498 | Disc Loss: 0.6503\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/100: 100%|██████████| 125/125 [00:28<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] | Gen Loss: 1.7203 | Disc Loss: 0.6502\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/100: 100%|██████████| 125/125 [00:27<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] | Gen Loss: 1.7116 | Disc Loss: 0.6503\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/100: 100%|██████████| 125/125 [00:26<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] | Gen Loss: 1.9936 | Disc Loss: 0.6504\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/100: 100%|██████████| 125/125 [00:26<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] | Gen Loss: 1.6673 | Disc Loss: 0.6502\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/100: 100%|██████████| 125/125 [00:27<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] | Gen Loss: 1.7452 | Disc Loss: 0.6502\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] | Gen Loss: 1.8536 | Disc Loss: 0.6547\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] | Gen Loss: 1.7274 | Disc Loss: 0.6503\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/100: 100%|██████████| 125/125 [00:26<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] | Gen Loss: 1.8248 | Disc Loss: 0.6517\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/100: 100%|██████████| 125/125 [00:26<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] | Gen Loss: 1.7577 | Disc Loss: 0.6502\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] | Gen Loss: 1.9975 | Disc Loss: 0.6504\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] | Gen Loss: 1.7863 | Disc Loss: 0.6502\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] | Gen Loss: 1.7540 | Disc Loss: 0.6505\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] | Gen Loss: 1.7511 | Disc Loss: 0.6513\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] | Gen Loss: 2.0917 | Disc Loss: 0.6506\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] | Gen Loss: 1.8281 | Disc Loss: 0.6503\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/100: 100%|██████████| 125/125 [00:26<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] | Gen Loss: 2.2573 | Disc Loss: 0.9171\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] | Gen Loss: 1.9959 | Disc Loss: 0.6567\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/100: 100%|██████████| 125/125 [00:26<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] | Gen Loss: 1.9048 | Disc Loss: 0.6528\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100] | Gen Loss: 2.1856 | Disc Loss: 0.6525\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100] | Gen Loss: 2.0350 | Disc Loss: 0.6520\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100] | Gen Loss: 2.1514 | Disc Loss: 0.6576\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100] | Gen Loss: 1.7985 | Disc Loss: 0.6546\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/100: 100%|██████████| 125/125 [00:28<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100] | Gen Loss: 2.0517 | Disc Loss: 0.6506\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/100: 100%|██████████| 125/125 [00:27<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] | Gen Loss: 2.0122 | Disc Loss: 0.6508\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51/100: 100%|██████████| 125/125 [00:26<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100] | Gen Loss: 1.9967 | Disc Loss: 0.6505\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100] | Gen Loss: 2.0547 | Disc Loss: 0.6540\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53/100: 100%|██████████| 125/125 [00:27<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100] | Gen Loss: 1.9898 | Disc Loss: 0.6507\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100] | Gen Loss: 2.0121 | Disc Loss: 0.6508\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100] | Gen Loss: 2.0181 | Disc Loss: 0.6503\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] | Gen Loss: 2.0590 | Disc Loss: 0.6509\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100] | Gen Loss: 2.0289 | Disc Loss: 0.6510\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100] | Gen Loss: 2.0109 | Disc Loss: 0.6504\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100] | Gen Loss: 1.9793 | Disc Loss: 0.6503\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] | Gen Loss: 1.9747 | Disc Loss: 0.6503\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100] | Gen Loss: 2.0906 | Disc Loss: 0.6512\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100] | Gen Loss: 2.0075 | Disc Loss: 0.6505\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100] | Gen Loss: 2.0578 | Disc Loss: 0.6502\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100] | Gen Loss: 2.0604 | Disc Loss: 0.6502\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100] | Gen Loss: 2.0829 | Disc Loss: 0.6507\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100] | Gen Loss: 2.0339 | Disc Loss: 0.6505\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100] | Gen Loss: 2.0507 | Disc Loss: 0.6513\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100] | Gen Loss: 2.0332 | Disc Loss: 0.6505\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100] | Gen Loss: 2.0733 | Disc Loss: 0.6511\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] | Gen Loss: 2.1204 | Disc Loss: 0.6509\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100] | Gen Loss: 2.0610 | Disc Loss: 0.6506\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100] | Gen Loss: 2.0661 | Disc Loss: 0.6504\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100] | Gen Loss: 2.0496 | Disc Loss: 0.6503\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100] | Gen Loss: 2.0168 | Disc Loss: 0.6506\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100] | Gen Loss: 2.0262 | Disc Loss: 0.6503\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100] | Gen Loss: 2.0806 | Disc Loss: 0.6504\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100] | Gen Loss: 2.0626 | Disc Loss: 0.6502\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100] | Gen Loss: 2.0378 | Disc Loss: 0.6502\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100] | Gen Loss: 2.0378 | Disc Loss: 0.6502\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100] | Gen Loss: 2.0351 | Disc Loss: 0.6503\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100] | Gen Loss: 2.0818 | Disc Loss: 0.6502\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100] | Gen Loss: 2.0168 | Disc Loss: 0.6502\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83/100: 100%|██████████| 125/125 [00:26<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100] | Gen Loss: 2.0597 | Disc Loss: 0.6505\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100] | Gen Loss: 2.0610 | Disc Loss: 0.6503\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100] | Gen Loss: 2.0505 | Disc Loss: 0.6504\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100] | Gen Loss: 2.0729 | Disc Loss: 0.6503\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100] | Gen Loss: 2.0518 | Disc Loss: 0.6503\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88/100: 100%|██████████| 125/125 [00:26<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100] | Gen Loss: 2.1266 | Disc Loss: 0.6505\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100] | Gen Loss: 2.1289 | Disc Loss: 0.6503\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90/100: 100%|██████████| 125/125 [00:26<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100] | Gen Loss: 2.0276 | Disc Loss: 0.6503\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100] | Gen Loss: 2.0291 | Disc Loss: 0.6506\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 92/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100] | Gen Loss: 2.0535 | Disc Loss: 0.6505\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100] | Gen Loss: 2.0136 | Disc Loss: 0.6506\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100] | Gen Loss: 2.0793 | Disc Loss: 0.6502\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100] | Gen Loss: 2.0798 | Disc Loss: 0.6503\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 96/100: 100%|██████████| 125/125 [00:26<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100] | Gen Loss: 2.0522 | Disc Loss: 0.6530\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 97/100: 100%|██████████| 125/125 [00:26<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100] | Gen Loss: 2.0699 | Disc Loss: 0.6503\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 98/100: 100%|██████████| 125/125 [00:26<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100] | Gen Loss: 2.0574 | Disc Loss: 0.6503\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 99/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100] | Gen Loss: 2.0735 | Disc Loss: 0.6502\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 100/100: 100%|██████████| 125/125 [00:26<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | Gen Loss: 2.0946 | Disc Loss: 0.6502\n"
     ]
    }
   ],
   "source": [
    "train_gan(generator, discriminator, data_loader, class_embedding_layer, num_epochs=100, noise_dim=noise_dim, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iLxRQh1dEpv"
   },
   "outputs": [],
   "source": [
    "optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=lr * 0.5, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTbO6SbAawN2",
    "outputId": "e28b5aee-b88e-4bb1-8e5e-f6bd85e8655e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and optimizers saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator_path = \"/content/drive/MyDrive/ML Project/Generation/generator.pth\"\n",
    "discriminator_path = \"/content/drive/MyDrive/ML Project/Generation/discriminator.pth\"\n",
    "optimizer_gen_path = \"/content/drive/MyDrive/ML Project/Generation/optimizer_gen.pth\"\n",
    "optimizer_disc_path = \"/content/drive/MyDrive/ML Project/Generation/optimizer_disc.pth\"\n",
    "\n",
    "\n",
    "torch.save(generator.state_dict(), generator_path)\n",
    "torch.save(discriminator.state_dict(), discriminator_path)\n",
    "torch.save(optimizer_gen.state_dict(), optimizer_gen_path)\n",
    "torch.save(optimizer_disc.state_dict(), optimizer_disc_path)\n",
    "\n",
    "print(\"Models and optimizers saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2JrgDlSazoT",
    "outputId": "6928c7a9-e1ff-4ddf-a8e4-0d9c65c057be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-0cdd79030e34>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator.load_state_dict(torch.load(generator_path))\n",
      "<ipython-input-30-0cdd79030e34>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  discriminator.load_state_dict(torch.load(discriminator_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and optimizers loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-0cdd79030e34>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer_gen.load_state_dict(torch.load(optimizer_gen_path))\n",
      "<ipython-input-30-0cdd79030e34>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer_disc.load_state_dict(torch.load(optimizer_disc_path))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noise_dim = 100  \n",
    "class_embedding_dim = 40  \n",
    "num_classes = 40\n",
    "generator = Generator(noise_dim=noise_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "optimizer_gen = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "generator.load_state_dict(torch.load(generator_path))\n",
    "discriminator.load_state_dict(torch.load(discriminator_path))\n",
    "optimizer_gen.load_state_dict(torch.load(optimizer_gen_path))\n",
    "optimizer_disc.load_state_dict(torch.load(optimizer_disc_path))\n",
    "\n",
    "print(\"Models and optimizers loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVpHapsLQnlo"
   },
   "outputs": [],
   "source": [
    "\n",
    "noise = torch.randn(1, noise_dim).to(device) \n",
    "\n",
    "class_id = torch.tensor([25]).to(device) \n",
    "\n",
    "\n",
    "class_embedding = class_embedding_layer(class_id)  \n",
    "\n",
    "generator.eval()  \n",
    "with torch.no_grad():  \n",
    "    fake_image = generator(noise, class_embedding)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "3yNSF9ahgDOu",
    "outputId": "63137dd7-2cfc-4382-80ae-b66c77070ccf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "unnormalize = transforms.Normalize(mean=[-0.5 / 0.5, -0.5 / 0.5, -0.5 / 0.5], std=[1 / 0.5, 1 / 0.5, 1 / 0.5])\n",
    "fake_image = unnormalize(fake_image.squeeze(0))  \n",
    "fake_image = fake_image.permute(1, 2, 0).cpu().numpy()  \n",
    "\n",
    "\n",
    "plt.imshow(fake_image.clip(0, 1))  \n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB00WysVgF8B"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "noise = torch.randn(batch_size, noise_dim).to(device) \n",
    "class_ids = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7]).to(device) \n",
    "class_embeddings = class_embedding_layer(class_ids) \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_images = generator(noise, class_embeddings)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3INqluqYiPK"
   },
   "source": [
    "## Generator with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULTnNA9UgIfY"
   },
   "outputs": [],
   "source": [
    "class GeneratorWithImage(nn.Module):\n",
    "    def __init__(self, noise_dim=100, class_dim=40, image_channels=3):\n",
    "        super(GeneratorWithImage, self).__init__()\n",
    "\n",
    "       \n",
    "        self.image_encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 64, kernel_size=4, stride=2, padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()  \n",
    "        )\n",
    "\n",
    "      \n",
    "        self.fc = nn.Linear(noise_dim + class_dim + 128 * 8 * 8, 4 * 4 * 1024) \n",
    "\n",
    "        \n",
    "        self.resblock1 = ResBlockUp(1024, 512)\n",
    "        self.resblock2 = ResBlockUp(512, 256)\n",
    "        self.resblock3 = ResBlockUp(256, 128)\n",
    "        self.resblock4 = ResBlockUp(128, 64)\n",
    "\n",
    "       \n",
    "        self.conv = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "        self.tanh = nn.Tanh() \n",
    "\n",
    "    def forward(self, noise, class_embedding, input_image):\n",
    "      \n",
    "        image_features = self.image_encoder(input_image) \n",
    "\n",
    "       \n",
    "        x = torch.cat([noise, class_embedding, image_features], dim=1)  \n",
    "       \n",
    "        x = self.fc(x).view(-1, 1024, 4, 4) \n",
    "\n",
    "        \n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.resblock4(x)\n",
    "\n",
    "       \n",
    "        x = self.conv(x)\n",
    "        return self.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdKrnmmpY0yK"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_gan(generator, discriminator, data_loader, class_embedding_layer, num_epochs=20, noise_dim=100, lr=0.0002):\n",
    "    \n",
    "    optimizer_gen = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=lr * 0.5, betas=(0.5, 0.999))  \n",
    "\n",
    "    \n",
    "    gan_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for batch in tqdm(data_loader, desc=f\"Training Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            \n",
    "            optimizer_disc.zero_grad()\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels).detach()\n",
    "            input_images = batch[\"image\"].to(device)  \n",
    "            fake_images = generator(noise, class_embedding, input_images)\n",
    "           \n",
    "\n",
    "            \n",
    "            real_images_noisy = images + 0.05 * torch.randn_like(images).to(device)\n",
    "            fake_images_noisy = fake_images.detach() + 0.05 * torch.randn_like(fake_images).to(device)\n",
    "\n",
    "            \n",
    "            real_labels = torch.full((batch_size, 1), 0.9, device=device)\n",
    "            fake_labels = torch.full((batch_size, 1), 0.1, device=device)\n",
    "\n",
    "           \n",
    "            real_loss = gan_loss_fn(discriminator(real_images_noisy, class_embeddings), real_labels)\n",
    "            fake_loss = gan_loss_fn(discriminator(fake_images_noisy, class_embeddings), fake_labels)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            optimizer_disc.step()\n",
    "\n",
    "            \n",
    "            optimizer_gen.zero_grad()\n",
    "\n",
    "            \n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            class_embeddings = class_embedding_layer(labels)\n",
    "            fake_images = generator(noise, class_embeddings)\n",
    "\n",
    "            \n",
    "            gen_loss = gan_loss_fn(discriminator(fake_images, class_embeddings), real_labels)\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] | Gen Loss: {gen_loss.item():.4f} | Disc Loss: {disc_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "KCsIAv2WY0MB",
    "outputId": "ea3efdae-dec2-4c7b-b115-73e86c839510"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5300ae18b436>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneratorWithImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_embedding_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-da3a6a767557>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, data_loader, class_embedding_layer, num_epochs, noise_dim, lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_embedding_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moptimizer_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Lower LR for Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "train_gan(GeneratorWithImage, discriminator, data_loader, class_embedding_layer, num_epochs=20, noise_dim=noise_dim, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zg-Rw6AOZLob"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "image_dataset = ImageDataset(image_folder=image_dir, labels_csv=labels_csv, transform=image_transforms)\n",
    "data_loader = DataLoader(image_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "noise_dim = 100\n",
    "class_dim = 40 \n",
    "lr = 0.0002\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "generator = Generator(noise_dim=noise_dim, class_dim=class_dim).to(device)\n",
    "discriminator = Discriminator(class_dim=class_dim).to(device)\n",
    "\n",
    "\n",
    "class_embedding_layer = nn.Embedding(num_embeddings=40, embedding_dim=40).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyznHPzWZqPb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8rMd_2bwlyB"
   },
   "source": [
    "## Using image feature vector as input to generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfztRYjq7tCZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-RTfKbWzh2W",
    "outputId": "285bb7b4-d952-48e8-d87d-9f08dab3e837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK9EJVXQzYVK"
   },
   "source": [
    "##### For training the resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SW-C7XCo8y82",
    "outputId": "c7794696-68de-40ee-eaa9-e00a9b1dddf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch [1/60]: 100%|██████████| 50/50 [08:26<00:00, 10.13s/it, acc=0.328, loss=2.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60] - Loss: 2.7924, Accuracy: 0.3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/60]: 100%|██████████| 50/50 [00:08<00:00,  6.21it/s, acc=0.702, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/60] - Loss: 1.2429, Accuracy: 0.7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/60]: 100%|██████████| 50/50 [00:06<00:00,  7.52it/s, acc=0.772, loss=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60] - Loss: 0.8734, Accuracy: 0.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/60]: 100%|██████████| 50/50 [00:08<00:00,  6.17it/s, acc=0.836, loss=0.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/60] - Loss: 0.6570, Accuracy: 0.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/60]: 100%|██████████| 50/50 [00:06<00:00,  7.32it/s, acc=0.844, loss=0.571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60] - Loss: 0.5700, Accuracy: 0.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/60]: 100%|██████████| 50/50 [00:08<00:00,  6.10it/s, acc=0.885, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/60] - Loss: 0.4483, Accuracy: 0.8853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/60]: 100%|██████████| 50/50 [00:07<00:00,  7.04it/s, acc=0.889, loss=0.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/60] - Loss: 0.3992, Accuracy: 0.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/60]: 100%|██████████| 50/50 [00:08<00:00,  6.07it/s, acc=0.888, loss=0.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/60] - Loss: 0.4089, Accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/60]: 100%|██████████| 50/50 [00:06<00:00,  7.25it/s, acc=0.898, loss=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/60] - Loss: 0.3836, Accuracy: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/60]: 100%|██████████| 50/50 [00:08<00:00,  6.20it/s, acc=0.907, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/60] - Loss: 0.3678, Accuracy: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/60]: 100%|██████████| 50/50 [00:06<00:00,  7.31it/s, acc=0.909, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/60] - Loss: 0.3682, Accuracy: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/60]: 100%|██████████| 50/50 [00:08<00:00,  6.17it/s, acc=0.909, loss=0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/60] - Loss: 0.3594, Accuracy: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/60]: 100%|██████████| 50/50 [00:06<00:00,  7.37it/s, acc=0.925, loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/60] - Loss: 0.3394, Accuracy: 0.9254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/60]: 100%|██████████| 50/50 [00:07<00:00,  6.26it/s, acc=0.913, loss=0.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/60] - Loss: 0.3489, Accuracy: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/60]: 100%|██████████| 50/50 [00:07<00:00,  7.07it/s, acc=0.905, loss=0.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/60] - Loss: 0.3729, Accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/60]: 100%|██████████| 50/50 [00:07<00:00,  6.46it/s, acc=0.906, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/60] - Loss: 0.3409, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/60]: 100%|██████████| 50/50 [00:07<00:00,  7.13it/s, acc=0.919, loss=0.347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/60] - Loss: 0.3465, Accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/60]: 100%|██████████| 50/50 [00:07<00:00,  6.47it/s, acc=0.916, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/60] - Loss: 0.3557, Accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/60]: 100%|██████████| 50/50 [00:07<00:00,  6.62it/s, acc=0.91, loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/60] - Loss: 0.3611, Accuracy: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/60]: 100%|██████████| 50/50 [00:07<00:00,  6.69it/s, acc=0.917, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/60] - Loss: 0.3407, Accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/60]: 100%|██████████| 50/50 [00:07<00:00,  6.45it/s, acc=0.917, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/60] - Loss: 0.3450, Accuracy: 0.9173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/60]: 100%|██████████| 50/50 [00:07<00:00,  6.87it/s, acc=0.912, loss=0.335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/60] - Loss: 0.3338, Accuracy: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/60]: 100%|██████████| 50/50 [00:07<00:00,  6.26it/s, acc=0.906, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/60] - Loss: 0.3707, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/60]: 100%|██████████| 50/50 [00:06<00:00,  7.18it/s, acc=0.912, loss=0.362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/60] - Loss: 0.3611, Accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/60]: 100%|██████████| 50/50 [00:08<00:00,  5.95it/s, acc=0.908, loss=0.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/60] - Loss: 0.3398, Accuracy: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/60]: 100%|██████████| 50/50 [00:07<00:00,  6.97it/s, acc=0.915, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/60] - Loss: 0.3504, Accuracy: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/60]: 100%|██████████| 50/50 [00:08<00:00,  6.00it/s, acc=0.917, loss=0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/60] - Loss: 0.3421, Accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/60]: 100%|██████████| 50/50 [00:07<00:00,  6.97it/s, acc=0.92, loss=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/60] - Loss: 0.3363, Accuracy: 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/60]: 100%|██████████| 50/50 [00:08<00:00,  5.93it/s, acc=0.912, loss=0.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/60] - Loss: 0.3487, Accuracy: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/60]: 100%|██████████| 50/50 [00:07<00:00,  6.73it/s, acc=0.914, loss=0.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/60] - Loss: 0.3495, Accuracy: 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/60]: 100%|██████████| 50/50 [00:08<00:00,  6.14it/s, acc=0.905, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/60] - Loss: 0.3584, Accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/60]: 100%|██████████| 50/50 [00:07<00:00,  6.57it/s, acc=0.915, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/60] - Loss: 0.3444, Accuracy: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/60]: 100%|██████████| 50/50 [00:07<00:00,  6.42it/s, acc=0.909, loss=0.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/60] - Loss: 0.3492, Accuracy: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/60]: 100%|██████████| 50/50 [00:08<00:00,  6.13it/s, acc=0.912, loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/60] - Loss: 0.3351, Accuracy: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/60]: 100%|██████████| 50/50 [00:07<00:00,  6.87it/s, acc=0.913, loss=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/60] - Loss: 0.3518, Accuracy: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/60]: 100%|██████████| 50/50 [00:08<00:00,  6.02it/s, acc=0.908, loss=0.356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/60] - Loss: 0.3554, Accuracy: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/60]: 100%|██████████| 50/50 [00:07<00:00,  6.96it/s, acc=0.919, loss=0.328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] - Loss: 0.3276, Accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/60]: 100%|██████████| 50/50 [00:08<00:00,  5.91it/s, acc=0.905, loss=0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/60] - Loss: 0.3592, Accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/60]: 100%|██████████| 50/50 [00:07<00:00,  6.96it/s, acc=0.921, loss=0.314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/60] - Loss: 0.3133, Accuracy: 0.9211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/60]: 100%|██████████| 50/50 [00:08<00:00,  6.11it/s, acc=0.9, loss=0.352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/60] - Loss: 0.3513, Accuracy: 0.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/60]: 100%|██████████| 50/50 [00:07<00:00,  6.88it/s, acc=0.914, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/60] - Loss: 0.3498, Accuracy: 0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/60]: 100%|██████████| 50/50 [00:08<00:00,  6.23it/s, acc=0.914, loss=0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/60] - Loss: 0.3593, Accuracy: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/60]: 100%|██████████| 50/50 [00:07<00:00,  6.73it/s, acc=0.902, loss=0.366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/60] - Loss: 0.3656, Accuracy: 0.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/60]: 100%|██████████| 50/50 [00:07<00:00,  6.45it/s, acc=0.91, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/60] - Loss: 0.3559, Accuracy: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/60]: 100%|██████████| 50/50 [00:07<00:00,  6.51it/s, acc=0.926, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/60] - Loss: 0.3409, Accuracy: 0.9261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/60]: 100%|██████████| 50/50 [00:07<00:00,  6.61it/s, acc=0.904, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/60] - Loss: 0.3563, Accuracy: 0.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/60]: 100%|██████████| 50/50 [00:07<00:00,  6.30it/s, acc=0.916, loss=0.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/60] - Loss: 0.3403, Accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/60]: 100%|██████████| 50/50 [00:06<00:00,  7.15it/s, acc=0.912, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/60] - Loss: 0.3451, Accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/60]: 100%|██████████| 50/50 [00:08<00:00,  6.15it/s, acc=0.912, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/60] - Loss: 0.3561, Accuracy: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/60]: 100%|██████████| 50/50 [00:06<00:00,  7.30it/s, acc=0.904, loss=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/60] - Loss: 0.3764, Accuracy: 0.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/60]: 100%|██████████| 50/50 [00:07<00:00,  6.31it/s, acc=0.914, loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/60] - Loss: 0.3384, Accuracy: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/60]: 100%|██████████| 50/50 [00:06<00:00,  7.39it/s, acc=0.914, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/60] - Loss: 0.3483, Accuracy: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/60]: 100%|██████████| 50/50 [00:08<00:00,  6.13it/s, acc=0.909, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/60] - Loss: 0.3502, Accuracy: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/60]: 100%|██████████| 50/50 [00:06<00:00,  7.42it/s, acc=0.913, loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/60] - Loss: 0.3355, Accuracy: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/60]: 100%|██████████| 50/50 [00:08<00:00,  6.22it/s, acc=0.909, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/60] - Loss: 0.3556, Accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/60]: 100%|██████████| 50/50 [00:06<00:00,  7.38it/s, acc=0.907, loss=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/60] - Loss: 0.3516, Accuracy: 0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/60]: 100%|██████████| 50/50 [00:07<00:00,  6.25it/s, acc=0.907, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/60] - Loss: 0.3441, Accuracy: 0.9073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/60]: 100%|██████████| 50/50 [00:06<00:00,  7.45it/s, acc=0.91, loss=0.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/60] - Loss: 0.3595, Accuracy: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/60]: 100%|██████████| 50/50 [00:07<00:00,  6.28it/s, acc=0.909, loss=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/60] - Loss: 0.3525, Accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/60]: 100%|██████████| 50/50 [00:06<00:00,  7.45it/s, acc=0.915, loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/60] - Loss: 0.3388, Accuracy: 0.9148\n",
      "Training complete!\n",
      "Model saved to /content/drive/MyDrive/resnet18_transfer_learning.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'in_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-788e238b0293>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mresnet_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m resnet_loaded.fc = nn.Sequential(\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'in_features'"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file)  \n",
    "        self.image_dir = image_dir  \n",
    "        self.transform = transform \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.labels_df.iloc[idx]['filename']\n",
    "        label = int(self.labels_df.iloc[idx]['label'])  \n",
    "\n",
    "        subfolder = filename.split('_')[0] \n",
    "        image_path = os.path.join(self.image_dir, subfolder, filename)\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")  \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, num_epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=lr) \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            loop.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "            loop.set_postfix(loss=(running_loss / (total / train_loader.batch_size)),\n",
    "                             acc=(correct / total))\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "image_dir = \"EpochHunters/Subset_128x128/Subset_128x128\"\n",
    "csv_file = \"EpochHunters/labels.csv\"\n",
    "batch_size = 32\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "num_classes = 40\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = CustomImageDataset(csv_file=csv_file, image_dir=image_dir, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(resnet.fc.in_features, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, num_classes) \n",
    ")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "\n",
    "train_model(resnet, train_loader, val_loader, device, num_epochs=num_epochs, lr=learning_rate)\n",
    "\n",
    "\n",
    "model_path = \"EpochHunters/resnet18_transfer_learning.pth\"\n",
    "torch.save(resnet.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZ2fKtmizG4c",
    "outputId": "7db8bce7-9b63-4c2e-f1f3-0eaf0856a19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Extracted Features Shape: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE IIT BHILAI\\AppData\\Local\\Temp\\ipykernel_14952\\1467027424.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_loaded.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "resnet_loaded = models.resnet18(pretrained=True)\n",
    "\n",
    "in_features = resnet_loaded.fc.in_features\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "resnet_loaded.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 512),  \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 40)  \n",
    ")\n",
    "model_path = \"EpochHunters/resnet18_transfer_learning.pth\"\n",
    "\n",
    "resnet_loaded.load_state_dict(torch.load(model_path))\n",
    "resnet_loaded = resnet_loaded.to(device)\n",
    "resnet_loaded.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(model, image_path, device, transform):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = transform(image).unsqueeze(0).to(device)  \n",
    "\n",
    "        \n",
    "        features = model.fc[0](model.avgpool(model.layer4(model.layer3(model.layer2(model.layer1(model.conv1(image)))))).view(1, -1))\n",
    "        return features\n",
    "\n",
    "\n",
    "sample_image_path = \"EpochHunters/Subset_128x128/Subset_128x128/n02106662/n02106662_10232.JPEG\"\n",
    "features = extract_features(resnet_loaded, sample_image_path, device, transform)\n",
    "print(f\"Extracted Features Shape: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "sORABdzQERWK",
    "outputId": "0baa5bc9-6f2e-4d1b-ca38-76ba849754d5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Real images\u001b[39;00m\n\u001b[0;32m    139\u001b[0m outputs \u001b[38;5;241m=\u001b[39m discriminator(real_images)\n\u001b[1;32m--> 140\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m criterion(outputs, real_labels)\n\u001b[0;32m    141\u001b[0m d_loss_real\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Fake images\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction\n\u001b[0;32m    699\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3548\u001b[0m     )\n\u001b[0;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "class ImageFeatureDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform, resnet_model, device):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.resnet_model = resnet_model\n",
    "        self.device = device\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {} \n",
    "\n",
    "        \n",
    "        class_idx = 0\n",
    "        for subfolder in os.listdir(image_dir):\n",
    "            subfolder_path = os.path.join(image_dir, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                self.class_to_idx[subfolder] = class_idx\n",
    "                for img_name in os.listdir(subfolder_path):\n",
    "                    if img_name.endswith('.JPEG'):\n",
    "                        self.image_paths.append(os.path.join(subfolder_path, img_name))\n",
    "                        self.labels.append(subfolder)  # Store the class name (subfolder name)\n",
    "                class_idx += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.class_to_idx[self.labels[idx]]  \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feature = self.resnet_model(image).squeeze(0)\n",
    "\n",
    "        return feature, label, img_path\n",
    "\n",
    "\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "in_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Identity()  \n",
    "resnet = resnet.to(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "image_dir = \"EpochHunters/Subset_128x128\"\n",
    "dataset = ImageFeatureDataset(image_dir=image_dir, transform=transform, resnet_model=resnet, device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, feature_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + feature_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 128*128*3)  \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z, features):\n",
    "        x = torch.cat((z, features), dim=1)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.tanh(x).view(-1, 3, 128, 128) \n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "z_dim = 100  \n",
    "feature_dim = 512 \n",
    "generator = Generator(z_dim, feature_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels, paths) in enumerate(dataloader):\n",
    "        batch_size = features.size(0) \n",
    "        z = torch.randn(batch_size, z_dim).to(device) \n",
    "        features = features.view(batch_size, -1)  \n",
    "\n",
    "        \n",
    "        fake_images = generator(z, features) \n",
    "\n",
    "       \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)  \n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device) \n",
    "\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "       \n",
    "        outputs = discriminator(real_images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        \n",
    "        outputs = discriminator(fake_images.detach()) \n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "\n",
    "       \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        outputs = discriminator(fake_images)  \n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], D Loss: {d_loss_real.item() + d_loss_fake.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKp3w4HBF_HD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
